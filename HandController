import React, { useEffect, useRef, useState } from 'react';
import { HandLandmarker, FilesetResolver } from '@mediapipe/tasks-vision';
import { ParticleState } from '../types';

interface HandControllerProps {
  onGesture: (state: ParticleState | null) => void;
  onRotation: (rotation: number) => void;
}

export const HandController: React.FC<HandControllerProps> = ({ onGesture, onRotation }) => {
  const videoRef = useRef<HTMLVideoElement>(null);
  const [loaded, setLoaded] = useState(false);
  
  useEffect(() => {
    let handLandmarker: HandLandmarker | null = null;
    let animationFrameId: number;

    const setupMediaPipe = async () => {
      try {
        const vision = await FilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
        );
        
        handLandmarker = await HandLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: `https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task`,
            delegate: "GPU"
          },
          runningMode: "VIDEO",
          numHands: 1
        });
        setLoaded(true);
        startWebcam();
      } catch (error) {
        console.error("Failed to load MediaPipe:", error);
      }
    };

    const startWebcam = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
          videoRef.current.addEventListener('loadeddata', predictWebcam);
        }
      } catch (err) {
        console.error("Error accessing webcam:", err);
      }
    };

    let lastVideoTime = -1;
    const predictWebcam = () => {
      if (videoRef.current && handLandmarker) {
        if (videoRef.current.currentTime !== lastVideoTime) {
          lastVideoTime = videoRef.current.currentTime;
          const startTimeMs = performance.now();
          const result = handLandmarker.detectForVideo(videoRef.current, startTimeMs);

          if (result.landmarks && result.landmarks.length > 0) {
            const landmarks = result.landmarks[0];
            
            // 1. Calculate Rotation (X-axis position)
            // Landmarks x is 0-1 (normalized). 0.5 is center.
            // Map 0 -> -2, 1 -> 2 (radians)
            const x = landmarks[0].x; // Wrist position
            // Invert x because video is mirrored
            const rotation = (0.5 - x) * 4; // Sensitivity factor
            onRotation(rotation);

            // 2. Gesture Detection
            // Simple logic: Is hand open or closed?
            // Measure distance of finger tips to wrist
            const wrist = landmarks[0];
            const tips = [8, 12, 16, 20]; // Index, Middle, Ring, Pinky tips
            
            let extendedFingers = 0;
            const threshold = 0.2; // Threshold for normalized coords

            tips.forEach(tipIdx => {
              const tip = landmarks[tipIdx];
              const dist = Math.sqrt(
                Math.pow(tip.x - wrist.x, 2) + 
                Math.pow(tip.y - wrist.y, 2)
              );
              if (dist > threshold) extendedFingers++;
            });

            // State Logic
            // If >= 3 fingers extended -> Open -> SCATTERED
            // If <= 1 finger extended -> Fist -> TREE_SHAPE
            
            if (extendedFingers >= 3) {
              onGesture(ParticleState.SCATTERED);
            } else if (extendedFingers <= 1) {
              onGesture(ParticleState.TREE_SHAPE);
            }
          }
        }
      }
      animationFrameId = requestAnimationFrame(predictWebcam);
    };

    setupMediaPipe();

    return () => {
      if (videoRef.current && videoRef.current.srcObject) {
         const tracks = (videoRef.current.srcObject as MediaStream).getTracks();
         tracks.forEach(track => track.stop());
      }
      cancelAnimationFrame(animationFrameId);
      if (handLandmarker) handLandmarker.close();
    };
  }, [onGesture, onRotation]);

  return (
    <div className="absolute bottom-4 right-4 z-50 pointer-events-auto">
      <div className={`
        relative w-32 h-24 bg-black/50 rounded-lg overflow-hidden border border-pink-500/30
        transition-opacity duration-1000 ${loaded ? 'opacity-100' : 'opacity-0'}
      `}>
         <video 
           ref={videoRef}
           className="w-full h-full object-cover transform -scale-x-100" // Mirror the video for natural interaction
           autoPlay
           playsInline
           muted
         />
         <div className="absolute top-1 left-2 text-[8px] text-pink-200 uppercase tracking-widest bg-black/40 px-1 rounded">
            Gesture Control
         </div>
      </div>
    </div>
  );
};
